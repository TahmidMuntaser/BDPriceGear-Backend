name: Hourly Product Scraping

on:
  schedule:
    # Run every hour at minute 0 UTC
    - cron: '0 * * * *'
  workflow_dispatch:  # Allow manual trigger

jobs:
  scrape-and-update:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Install Playwright browsers
        run: |
          playwright install chromium
          playwright install-deps chromium

      - name: Scrape products and update Supabase
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          DJANGO_SETTINGS_MODULE: core.settings
          PYTHONPATH: /github/workspace/bdpricegear-backend
          PLAYWRIGHT_BROWSERS_PATH: 0
        working-directory: ./bdpricegear-backend
        run: |
          echo "ðŸ”„ Starting hourly product scrape..."
          python manage.py populate_products --limit 1500
          echo "âœ… Products scraped and saved to Supabase"

      - name: Verify products in database
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          DJANGO_SETTINGS_MODULE: core.settings
          PYTHONPATH: /github/workspace/bdpricegear-backend
        working-directory: ./bdpricegear-backend
        run: |
          python manage.py shell << 'EOF'
          from products.models import Product
          count = Product.objects.count()
          print(f"âœ… Total products in Supabase: {count}")
          EOF

      - name: âœ… Scrape completed
        if: success()
        run: echo "ðŸŽ‰ Hourly scrape and Supabase update completed successfully"

      - name: âŒ Scrape failed
        if: failure()
        run: echo "âš ï¸ Hourly scrape failed - check logs"
        run: echo "Scraping completed successfully"
      
      - name: âŒ Scraping failed
        if: failure()
        run: echo "Scraping failed - check logs"
